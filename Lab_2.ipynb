{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><b>Лабораторная работа 2.</b> Разработка и запуск MapReduce приложений</div><hr>\n",
    "<div style=\"text-align:right;\">Папулин С.Ю. <span style=\"font-style: italic;font-weight: bold;\">(papulin_bmstu@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"0\"></a>\n",
    "<div><span style=\"font-size:14pt; font-weight:bold\">Содержание</span>\n",
    "    <ol>\n",
    "        <li><a href=\"#1\">Разработка приложений MapReduce с ипользованием IDE Eclipse</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#1a\">Исходный код программы</a></li>\n",
    "                <li><a href=\"#1b\">Запуск проекта</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#2\">Запуск приложения MapReduce</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#2a\">Запуск на локальной версии Cloudera</a></li>\n",
    "                <li><a href=\"#2b\">Запуск на кластере EMR AWS</a></li>\n",
    "                <li><a href=\"#2c\">Запуск на кластере HDInsight Azure</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#5\">Источники</a>\n",
    "        </li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <p><b>Цель лабораторной работы</b> - освоить:</p>\n",
    "    <ol>\n",
    "        <li>создание проектов MapReduce с использованием среды разработки Eclipse</li>\n",
    "        <li>запуск приложений MapReduce на Hadoop кластере</li>\n",
    "        <li>подключение к средствам мониторинга ресурсов Hadoop кластер</li>\n",
    "    </ol>\n",
    "    <p><b>Необходимые средства и схема подключения</b></p>\n",
    "    <img src=\"img/structure_tools.png\" alt=\"Tools for Lab 2\" width=\"60%\" style=\"max-width:500px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">1. Разработка приложений MapReduce с ипользованием IDE Eclipse</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"1a\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Исходный код программы\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#1b\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ota.ox.ac.uk/text/5721.txt - датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://hadoop.apache.org/docs/r2.7.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import java.io.IOException;\n",
    "import java.util.StringTokenizer;\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "import org.apache.hadoop.mapreduce.Mapper;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "\n",
    "public class WordCount {\n",
    "\n",
    "  public static class TokenizerMapper\n",
    "       extends Mapper<Object, Text, Text, IntWritable>{\n",
    "\n",
    "    private final static IntWritable one = new IntWritable(1);\n",
    "    private Text word = new Text();\n",
    "\n",
    "    public void map(Object key, Text value, Context context\n",
    "                    ) throws IOException, InterruptedException {\n",
    "      StringTokenizer itr = new StringTokenizer(value.toString());\n",
    "      while (itr.hasMoreTokens()) {\n",
    "        word.set(itr.nextToken());\n",
    "        context.write(word, one);\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  public static class IntSumReducer\n",
    "       extends Reducer<Text,IntWritable,Text,IntWritable> {\n",
    "    private IntWritable result = new IntWritable();\n",
    "\n",
    "    public void reduce(Text key, Iterable<IntWritable> values,\n",
    "                       Context context\n",
    "                       ) throws IOException, InterruptedException {\n",
    "      int sum = 0;\n",
    "      for (IntWritable val : values) {\n",
    "        sum += val.get();\n",
    "      }\n",
    "      result.set(sum);\n",
    "      context.write(key, result);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) throws Exception {\n",
    "    Configuration conf = new Configuration();\n",
    "    Job job = Job.getInstance(conf, \"word count\");\n",
    "    job.setJarByClass(WordCount.class);\n",
    "    job.setMapperClass(TokenizerMapper.class);\n",
    "    job.setCombinerClass(IntSumReducer.class);\n",
    "    job.setReducerClass(IntSumReducer.class);\n",
    "    job.setOutputKeyClass(Text.class);\n",
    "    job.setOutputValueClass(IntWritable.class);\n",
    "    FileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "    FileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
    "    System.exit(job.waitForCompletion(true) ? 0 : 1);\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходный код программы на Scala (см. также https://github.com/twitter/scalding )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.hadoop.conf.Configuration\n",
    "import org.apache.hadoop.fs.Path\n",
    "import org.apache.hadoop.io.IntWritable\n",
    "import org.apache.hadoop.io.Text\n",
    "import org.apache.hadoop.mapreduce.Job\n",
    "import org.apache.hadoop.mapreduce.Mapper\n",
    "import org.apache.hadoop.mapreduce.Reducer\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat\n",
    "import org.apache.hadoop.util.GenericOptionsParser\n",
    "import scala.collection.JavaConversions._\n",
    "\n",
    "// This class performs the map operation, translating raw input into the key-value\n",
    "// pairs we will feed into our reduce operation.\n",
    "class TokenizerMapper extends Mapper[Object, Text, Text, IntWritable] {\n",
    "  val one = new IntWritable(1)\n",
    "  val word = new Text\n",
    "\n",
    "  override\n",
    "  def map(key: Object, value: Text, context: Mapper[Object, Text, Text, IntWritable]#Context) = {\n",
    "    for (t <- value.toString.split(\"\\\\s\")) {\n",
    "      word.set(t)\n",
    "      context.write(word, one)\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "// This class performs the reduce operation, iterating over the key-value pairs\n",
    "// produced by our map operation to produce a result. In this case we just\n",
    "// calculate a simple total for each word seen.\n",
    "class IntSumReducer extends Reducer[Text, IntWritable, Text, IntWritable] {\n",
    "  override\n",
    "  def reduce(key: Text, values: java.lang.Iterable[IntWritable], context: Reducer[Text, IntWritable, Text, IntWritable]#Context) = {\n",
    "    val sum = values.foldLeft(0) { (t, i) => t + i.get }\n",
    "    context.write(key, new IntWritable(sum))\n",
    "  }\n",
    "}\n",
    "\n",
    "// This class configures and runs the job with the map and reduce classes we've\n",
    "// specified above.\n",
    "object WordCount extends App {\n",
    "\n",
    "  val conf = new Configuration()\n",
    "  val otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs\n",
    "  if (otherArgs.length != 2) {\n",
    "    println(\"Usage: wordcount <in> <out>\")\n",
    "    sys.exit(2)\n",
    "  }\n",
    "  val job = Job.getInstance(conf, \"word count\")\n",
    "  job.setJarByClass(classOf[TokenizerMapper])\n",
    "  job.setMapperClass(classOf[TokenizerMapper])\n",
    "  job.setCombinerClass(classOf[IntSumReducer])\n",
    "  job.setReducerClass(classOf[IntSumReducer])\n",
    "  job.setOutputKeyClass(classOf[Text])\n",
    "  job.setOutputValueClass(classOf[IntWritable])\n",
    "  FileInputFormat.addInputPath(job, new Path(args(0)))\n",
    "  FileOutputFormat.setOutputPath(job, new Path(args(1)))\n",
    "  sys.exit(if (job.waitForCompletion(true)) 0 else 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скрипт для сборки Scala проекта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name := \"map_reduce\"\n",
    " \n",
    "version := \"1.0\"\n",
    " \n",
    "scalaVersion := \"2.11.8\"\n",
    "\n",
    "libraryDependencies += \"org.apache.hadoop\" % \"hadoop-client\" % \"2.7.3\"\n",
    "libraryDependencies += \"org.scalatest\" %% \"scalatest\" % \"3.0.0\" % \"test\"\n",
    "\n",
    "assemblyMergeStrategy in assembly := {\n",
    "  case PathList(\"META-INF\", \"MANIFEST.MF\") => MergeStrategy.discard\n",
    "  case _ => MergeStrategy.first\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"1b\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Запуск проекта\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#1b\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Самостоятельное добавлние пакетов Hadoop в проект</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Java -> JAR <br>\n",
    "https://www.cs.utexas.edu/~scottm/cs307/handouts/Eclipse%20Help/jarInEclipse.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сборка зависимостей с использованием Maven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://tutorials.pcdhan.com/hadoop/developing-your-first-mapreduce-app-in-java-using-eclipse-and-maven/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">2. Запуск приложения MapReduce</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"2a\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Запуск на локальной версии Cloudera\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2b\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <p><b>Схема подключения</b></p>\n",
    "    <img src=\"img/connection_cloudera.png\" alt=\"Tools for Lab 2\" width=\"30%\" style=\"max-width:300px;min-width:200px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Подготовка исходных файлов с данными и выполняемой программой MapReduce</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование файла с исходными данными на узел кластера</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"border: 1px solid lightgrey; padding: 5px 5px 5px 5px; font-family: Courier New\">\n",
    "<span style=\"color: green; font-weight: bold\">scp</span>\n",
    "/home/sergo/downloads/Datasets/ROMEO_and_IVLIET.txt\n",
    "cloudera@192.168.42.29:/home/cloudera/wiil.csv</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scp /home/sergo/downloads/Datasets/ROMEO_and_IVLIET.txt cloudera@192.168.42.29:/home/cloudera/wiil.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование выполняемого файла jar на узел кластера</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scp /home/sergo/downloads/hadoop_mr-0.0.1-SNAPSHOT.jar cloudera@192.168.42.29:/home/cloudera/hadoop_mr-0.0.1-SNAPSHOT.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Подключение к кластеру</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sudo ssh 192.168.42.29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование файла с исходными данными из локальной папки в HDFS </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -copyFromLocal /home/cloudera/wiil.csv /user/root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Запуск приложения MapReduce</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Команда запуска</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop jar /home/cloudera/hadoop_mr-0.0.1-SNAPSHOT.jar bigdata.labs.WordCount /user/root/wiil.csv /user/root/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Проверка выполнения</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><i>Проверка выходных файлов в HDFS</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отображение списка папок и файлов HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls /user/root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Рекурсивное отображение списка папок и файлов HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls -R /user/root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка наличия выходных файлов в папке HDFS \"/user/root/output\"</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls /user/root/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop fs -ls /user/root/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><i>Подключение к панели ResourсeManager</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"2b\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Запуск на кластере EMR AWS  \n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2a\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2c\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <p><b>Схема подключения</b></p>\n",
    "    <img src=\"img/connection_aws.png\" alt=\"Tools for Lab 2\" width=\"50%\" style=\"max-width:500px;min-width:300px;\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Развертывание кластера EMR</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/gsg-launch-cluster.html\">Launch an Amazon EMR Cluster</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Подключение к кластеру</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "CLUSTER_DNS=YOUR_DNS\n",
    "KEY_PATH=YOUR_KEY.pem\n",
    "\n",
    "ssh -i $KEY_PATH hadoop@$CLUSTER_DNS #ssh connection\n",
    "hdfs version #hdfs version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка соединения</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование папки с исходными файлами на машину кластера ERM</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scp -i YOUR_KEY.pem -rp /home/sergo/downloads/WordCount-Files hadoop@YOUR_DNS:/tmp/mr-job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование файла с исходными данными из локальной папки в HDFS </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -copyFromLocal /tmp/mr-job/ROMEO_and_IVLIET.txt /user/root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка записи файла</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls /user/root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs fsck /user/root/ROMEO_and_IVLIET.txt -files -blocks -locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Запуск приложения MapReduce</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop jar /tmp/mr-job/hadoop_mr-0.0.1-SNAPSHOT.jar bigdata.labs.WordCount /user/root/ROMEO_and_IVLIET.txt /user/root/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка выполнения</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls /user/root/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -tail /user/root/output/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Развертывание кластера EMR и запуск приложения посредством AWS CLI</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Конфигурирование доступа к кластеру через AWS CLI</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "KEY_ID=YOUR_KEY\n",
    "ACCESS_KEY=YOUR_ACCES\n",
    "REGION=YOUR_REGION\n",
    "\n",
    "aws configure set aws_access_key_id $KEY_ID\n",
    "aws configure set aws_secret_access_key $ACCESS_KEY\n",
    "aws configure set region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отображение бакетов S3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 ls --recursive --human-readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Создание нового бакета</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 mb s3://aws-mr-jobs-labs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование файлов с исходными данными из локальной папки в S3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 cp /home/sergo/downloads/WordCount-Files s3://aws-mr-jobs-labs/lab2 --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Развертывание кластера и запуск приложения MapReduce</p>\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-launch-custom-jar-cli.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws emr create-cluster --name \"Hadoop_WordCount\" \\\n",
    "--ami-version 3.11.0 \\\n",
    "--log-uri s3://aws-mr-jobs-labs/lab2/logs/ \\\n",
    "--use-default-roles \\\n",
    "--ec2-attributes KeyName=hadoop_keys,SubnetId=subnet-<your-subnet-id> \\\n",
    "--instance-type m4.large \\\n",
    "--instance-count 3 \\\n",
    "--\n",
    "--steps 'Type=CUSTOM_JAR,Name=\"WordCount_JAR_Step\",ActionOnFailure=CONTINUE,Jar=s3://aws-mr-jobs-labs/lab2/hadoop_mr-0.0.1-SNAPSHOT.jar,MainClass=bigdata.labs.WordCount,Args=[\"s3://aws-mr-jobs-labs/lab2/ROMEO_and_IVLIET.txt\",\"s3://aws-mr-jobs-labs/lab2/output\"]'\n",
    "#--applications Name=Hue Name=Hive Name=Pig \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка выполнения</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 ls s3://aws-mr-jobs-labs/lab2/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 cp s3://aws-mr-jobs-labs/lab2/output/part-r-00000 /home/sergo/downloads/part-r-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "tail /home/sergo/downloads/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Подключение к панели ResourceManager</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Удаление папки с резульататом работы MapReduce</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 rm s3://aws-mr-jobs-labs/lab2/output --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"2с\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            с. Запуск на кластере HDInsight Azure  \n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2b\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#3\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Запуск с хоста в кластере</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключения к машине в кластере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# узнать строку подключения можно кликнув на ваш кластер на portal.azure.com (см. вверху вкладку \"Безопасная оболочка\")\n",
    "ssh username@user-cluster-ssh.azurehdinsight.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С локального хоста необходимо скопировать jar-файл с кодом и датасет на машину кластера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "scp wordcount.jar username@user-cluster-ssh.azurehdinsight.net:/home/username\n",
    "scp data.txt username@user-cluster-ssh.azurehdinsight.net:/home/username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее сохраним данные, которые мы собираемся обработать, на распределенной файловой системе (jar-файл в свою очередь доступен по локальному пути)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# альтернативный синтаксис hdfs dfs\n",
    "hadoop fs -mkdir /user/root/WordCount\n",
    "hadoop fs -copyFromLocal data.txt /user/root/WordCount/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь с машины в кластере мы можем запустить MapReduce job. Обратите внимение, что MS Azure для хранения использует Blob storage - своего рода обертка над HDFS, поэтому URL до директории с результатами работы программы имеет префикс \"wasbs://\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# yarn jar <jar-файл> <имя запускаемого класса> <данные для обработки> <директория с результатами работы>\n",
    "yarn jar wordcount.jar WordCount \\\n",
    "    wasb:///user/root/WordCount/data.txt wasb:///user/root/WordCount/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнив команду \"hadoop fs -ls /user/root/WordCount/output/\" вы увидете 2 файла: SUCCESS (говорит о том, что job выполнился успешно) и part-r-00000 - это и есть файл с результатами, выведем его содержимое на экран"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "hadoop fs -cat /user/root/WordCount/output/part-r-00000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
