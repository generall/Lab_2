{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><b>Лабораторная работа 2.</b> Разработка и запуск MapReduce приложений</div><hr>\n",
    "<div style=\"text-align:right;\">Папулин С.Ю. <span style=\"font-style: italic;font-weight: bold;\">(papulin_bmstu@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"0\"></a>\n",
    "<div><span style=\"font-size:14pt; font-weight:bold\">Содержание</span>\n",
    "    <ol>\n",
    "        <li><a href=\"#1\">Разработка приложений MapReduce с ипользованием IDE Eclipse</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#1a\">Исходный код программы</a></li>\n",
    "                <li><a href=\"#1b\">Запуск проекта</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#2\">Запуск приложения MapReduce</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#2a\">Запуск на локальной версии Cloudera</a></li>\n",
    "                <li><a href=\"#2b\">Запуск на кластере EMR AWS</a></li>\n",
    "                <li><a href=\"#2c\">Запуск на кластере HDInsight Azure</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#5\">Источники</a>\n",
    "        </li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">1. Разработка приложений MapReduce с ипользованием IDE Eclipse</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"1a\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Исходный код программы\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#1b\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ota.ox.ac.uk/text/5721.txt - датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://hadoop.apache.org/docs/r2.7.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import java.io.IOException;\n",
    "import java.util.StringTokenizer;\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "import org.apache.hadoop.mapreduce.Mapper;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "\n",
    "public class WordCount {\n",
    "\n",
    "  public static class TokenizerMapper\n",
    "       extends Mapper<Object, Text, Text, IntWritable>{\n",
    "\n",
    "    private final static IntWritable one = new IntWritable(1);\n",
    "    private Text word = new Text();\n",
    "\n",
    "    public void map(Object key, Text value, Context context\n",
    "                    ) throws IOException, InterruptedException {\n",
    "      StringTokenizer itr = new StringTokenizer(value.toString());\n",
    "      while (itr.hasMoreTokens()) {\n",
    "        word.set(itr.nextToken());\n",
    "        context.write(word, one);\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  public static class IntSumReducer\n",
    "       extends Reducer<Text,IntWritable,Text,IntWritable> {\n",
    "    private IntWritable result = new IntWritable();\n",
    "\n",
    "    public void reduce(Text key, Iterable<IntWritable> values,\n",
    "                       Context context\n",
    "                       ) throws IOException, InterruptedException {\n",
    "      int sum = 0;\n",
    "      for (IntWritable val : values) {\n",
    "        sum += val.get();\n",
    "      }\n",
    "      result.set(sum);\n",
    "      context.write(key, result);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) throws Exception {\n",
    "    Configuration conf = new Configuration();\n",
    "    Job job = Job.getInstance(conf, \"word count\");\n",
    "    job.setJarByClass(WordCount.class);\n",
    "    job.setMapperClass(TokenizerMapper.class);\n",
    "    job.setCombinerClass(IntSumReducer.class);\n",
    "    job.setReducerClass(IntSumReducer.class);\n",
    "    job.setOutputKeyClass(Text.class);\n",
    "    job.setOutputValueClass(IntWritable.class);\n",
    "    FileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "    FileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
    "    System.exit(job.waitForCompletion(true) ? 0 : 1);\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"1b\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Запуск проекта\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#1b\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Самостоятельное добавлние пакетов Hadoop в проект</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Java -> JAR <br>\n",
    "https://www.cs.utexas.edu/~scottm/cs307/handouts/Eclipse%20Help/jarInEclipse.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сборка зависимостей с использованием Maven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://tutorials.pcdhan.com/hadoop/developing-your-first-mapreduce-app-in-java-using-eclipse-and-maven/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">2. Запуск приложения MapReduce</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"2a\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Запуск на локальной версии Cloudera\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2b\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Подготовка исходных файлов с данными и выполняемой программой MapReduce</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование файла с исходными данными на узел кластера</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"border: 1px solid lightgrey; padding: 5px 5px 5px 5px; font-family: Courier New\">\n",
    "<span style=\"color: green; font-weight: bold\">scp</span>\n",
    "/home/sergo/downloads/Datasets/ROMEO_and_IVLIET.txt\n",
    "cloudera@192.168.42.29:/home/cloudera/wiil.csv</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scp /home/sergo/downloads/Datasets/ROMEO_and_IVLIET.txt cloudera@192.168.42.29:/home/cloudera/wiil.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование выполняемого файла jar на узел кластера</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scp /home/sergo/downloads/hadoop_mr-0.0.1-SNAPSHOT.jar cloudera@192.168.42.29:/home/cloudera/hadoop_mr-0.0.1-SNAPSHOT.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Подключение к кластеру</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sudo ssh 192.168.42.29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование файла с исходными данными из локальной папки в HDFS </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -copyFromLocal /home/cloudera/wiil.csv /user/root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Запуск приложения MapReduce</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Команда запуска</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop jar /home/cloudera/hadoop_mr-0.0.1-SNAPSHOT.jar bigdata.labs.WordCount /user/root/wiil.csv /user/root/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Проверка выполнения</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><i>Проверка выходных файлов в HDFS</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отображение списка папок и файлов HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls /user/root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Рекурсивное отображение списка папок и файлов HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls -R /user/root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка наличия выходных файлов в папке HDFS \"/user/root/output\"</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls /user/root/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop fs -ls /user/root/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><i>Подключение к панели ResourсeManager</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"2b\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Запуск на кластере EMR AWS  \n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2a\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2c\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Развертывание кластера EMR</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/gsg-launch-cluster.html\">Launch an Amazon EMR Cluster</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Подключение к кластеру</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "CLUSTER_DNS=YOUR_DNS\n",
    "KEY_PATH=YOUR_KEY.pem\n",
    "\n",
    "ssh -i $KEY_PATH hadoop@$CLUSTER_DNS #ssh connection\n",
    "hdfs version #hdfs version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка соединения</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование папки с исходными файлами на машину кластера ERM</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scp -i YOUR_KEY.pem -rp /home/sergo/downloads/WordCount-Files hadoop@YOUR_DNS:/tmp/mr-job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование файла с исходными данными из локальной папки в HDFS </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -copyFromLocal /tmp/mr-job/ROMEO_and_IVLIET.txt /user/root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка записи файла</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls /user/root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs fsck /user/root/ROMEO_and_IVLIET.txt -files -blocks -locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Запуск приложения MapReduce</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop jar /tmp/mr-job/hadoop_mr-0.0.1-SNAPSHOT.jar bigdata.labs.WordCount /user/root/ROMEO_and_IVLIET.txt /user/root/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка выполнения</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls /user/root/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -tail /user/root/output/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Развертывание кластера EMR и запуск приложения посредством AWS CLI</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Конфигурирование доступа к кластеру через AWS CLI</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "KEY_ID=YOUR_KEY\n",
    "ACCESS_KEY=YOUR_ACCES\n",
    "REGION=YOUR_REGION\n",
    "\n",
    "aws configure set aws_access_key_id $KEY_ID\n",
    "aws configure set aws_secret_access_key $ACCESS_KEY\n",
    "aws configure set region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отображение бакетов S3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Создание нового бакета</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 mb s3://aws-mr-jobs-labs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копирование файлов с исходными данными из локальной папки в S3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 cp /home/sergo/downloads/WordCount-Files s3://aws-mr-jobs-labs/lab2 --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Развертывание кластера и запуск приложения MapReduce</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-launch-custom-jar-cli.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws emr create-cluster --name \"Hadoop_WordCount\" \\\n",
    "--ami-version 3.11.0 \\\n",
    "--use-default-roles \\\n",
    "--instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=t2.micro InstanceGroupType=CORE,InstanceCount=1,InstanceType=t2.nano "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws emr create-cluster --name \"Hadoop_WordCount\" \\\n",
    "--ami-version 3.11.0 \\\n",
    "--log-uri s3://aws-mr-jobs-labs/lab2/logs/ \\\n",
    "--use-default-roles \\\n",
    "--ec2-attributes KeyName=hadoop_keys \\\n",
    "--instance-type m1.medium \\\n",
    "--instance-count 3 \\\n",
    "--steps Type=CUSTOM_JAR,Name=\"WordCount_JAR_Step\",ActionOnFailure=CONTINUE,Jar=s3://aws-mr-jobs-labs/lab2/hadoop_mr-0.0.1-SNAPSHOT.jar,MainClass=bigdata.labs.WordCount,Args=[\"s3://aws-mr-jobs-labs/lab2/ROMEO_and_IVLIET.txt\",\"s3://aws-mr-jobs-labs/lab2/output\"]\n",
    "#--applications Name=Hue Name=Hive Name=Pig \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка выполнения</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 ls s3://aws-mr-jobs-labs/lab2/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 cp s3://aws-mr-jobs-labs/lab2/output/part-r-00000 /home/sergo/downloads/part-r-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "tail /home/sergo/downloads/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Подключение к панели ResourceManager</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Удаление папки с резульататом работы MapReduce</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 rm s3://aws-mr-jobs-labs/lab2/output --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"2с\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            с. Запуск на кластере HDInsight Azure  \n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2b\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#3\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">3. Запуск приложения MapReduce с Hadoop Streaming</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Использование Python</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Полный путь к файлам, в которых будет храниться код для Map и Reduce</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_python_file = \"/home/sergo/Labs/Lab2/Py_Code/wordcount_mapper.py\"\n",
    "reduce_python_file = \"/home/sergo/Labs/Lab2/Py_Code/wordcount_reduce.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Map</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile $map_python_file\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line = line.split()\n",
    "    for key in line:\n",
    "        value = 4\n",
    "        print('%s\\t%i' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка записи файла</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load ~/Labs/Lab2/Py_Code/wordcount_mapper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Reduce</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile $reduce_python_file\n",
    "import sys\n",
    "\n",
    "last_key = None\n",
    "running_total = 0\n",
    "\n",
    "for input_line in sys.stdin:\n",
    "    input_line = input_line.strip()\n",
    "    this_key, value = input_line.split(\"\\t\", 1)\n",
    "    value = int(value)\n",
    "    \n",
    "    if last_key == this_key:\n",
    "        running_total += value\n",
    "    else:\n",
    "        if last_key:\n",
    "            print(\"%s\\t%i\" % (last_key, running_total))\n",
    "    \n",
    "        running_total = value\n",
    "        last_key = this_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Простой тест Map и Reduce без Hadoop</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Для Map</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "MAP_PATH=~/Labs/Lab2/Py_Code/wordcount_mapper.py\n",
    "DATA_SOURCE_PATH=/home/sergo/downloads/WordCount-Files/ROMEO_and_IVLIET.txt\n",
    "\n",
    "cat $DATA_SOURCE_PATH | python $MAP_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Для Map-Reduce</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "MAP_PATH=~/Labs/Lab2/Py_Code/wordcount_mapper.py\n",
    "REDUCE_PATH=~/Labs/Lab2/Py_Code/wordcount_reduce.py\n",
    "DATA_SOURCE_PATH=/home/sergo/downloads/WordCount-Files/ROMEO_and_IVLIET.txt\n",
    "\n",
    "cat $DATA_SOURCE_PATH | python $MAP_PATH | sort | python $REDUCE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Запуск на локальной версии Cloudera</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Удаляем папку output, если она уже существует</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh 192.168.42.29\n",
    "\n",
    "hdfs dfs -rm -r /user/root/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Копируем исходные файлы Map и Reduce в Cloudera</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "MAP_PATH=~/Labs/Lab2/Py_Code/wordcount_mapper.py\n",
    "REDUCE_PATH=~/Labs/Lab2/Py_Code/wordcount_reduce.py\n",
    "\n",
    "scp $MAP_PATH $REDUCE_PATH cloudera@192.168.42.29:/home/cloudera/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Преверяем, что файлы были скопированны</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh 192.168.42.29\n",
    "\n",
    "ls /home/cloudera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Запускаем код под Hadoop Streaming</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh 192.168.42.29\n",
    "\n",
    "MAP_PATH=/home/cloudera/wordcount_mapper.py\n",
    "REDUCE_PATH=/home/cloudera/wordcount_reduce.py\n",
    "INPUT_HDFS=/user/root/wiil.csv\n",
    "OUTPUT_HDFS=/user/root/output\n",
    "\n",
    "hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \\\n",
    "    -D mapreduce.job.reduces=2 \\\n",
    "    -mapper \"python $MAP_PATH\" \\\n",
    "    -reducer \"python $REDUCE_PATH\" \\\n",
    "    -input $INPUT_HDFS \\\n",
    "    -output $OUTPUT_HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверяем результат выполнения</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh 192.168.42.29\n",
    "\n",
    "hdfs dfs -ls /user/root/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh 192.168.42.29\n",
    "\n",
    "hdfs dfs -tail /user/root/output/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
